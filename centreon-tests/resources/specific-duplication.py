from robot.api import logger
from subprocess import getoutput
import re
import json
import time
from dateutil import parser
from datetime import datetime


##
# @brief Given two files with md5 as rows, this function checks the first list
# contains the same md5 as the second list. There are exceptions in these files
# that's why we need a function to make this test.
#
# @param str The first file name
# @param str The second file name
#
# @return A boolean True on success
def files_contains_same_md5(file_e: str, file_b: str):

    getoutput("awk '{{print $8}}' {0} > {0}.md5".format(file_e))
    getoutput("awk '{{print $8}}' {0} > {0}.md5".format(file_b))

    f1 = open("{}.md5".format(file_e))
    content1 = f1.readlines()

    f2 = open("{}.md5".format(file_b))
    content2 = f2.readlines()

    idx1 = 0
    idx2 = 0

    while idx1 < len(content1) and idx2 < len(content2):
        if content1[idx1] == "test1.lua\n":
            idx1 += 1

        if content2[idx2] == "test.lua\n":
            idx2 += 1
            if content2[idx2] == "055b1a6348a16305474b60de439a0efd\n":
                idx2 += 1
            else:
                return False

        if content1[idx1] == content2[idx2]:
            idx1 += 1
            idx2 += 1
        else:
            return False
    return idx1 == len(content1) and idx2 == len(content2)

##
# @brief Given two files generated by a stream connector, this function checks
# that no events except special ones are sent / replayed twice.
#
# @param str The first file name
# @param str The second file name
#
# @return A boolean True on success
def check_multiplicity_when_broker_restarted(file1: str, file2: str):
    f1 = open(file1)
    content1 = f1.readlines()
    f2 = open(file2)
    content2 = f2.readlines()

    r = re.compile(r".* INFO: ([0-9]+)\s+([0-9a-f]+)\s(.*)$")

    def create_md5_list(content):
        lst = dict()
        for l in content:
            m = r.match(l)
            if m:
                type, md5, js = int(m.group(1)), m.group(2), m.group(3)
                if type != 65544 and type != 4294901762 and type != 196613:
                    if md5 in lst:
                        lst[md5] += 1
                    else:
                        lst[md5] = 1
        return lst

    lst1 = create_md5_list(content1)
    lst2 = create_md5_list(content2)

    res1 = set(lst1.values())
    res2 = set(lst2.values())
    if len(res1) > 1:
      logger.console("Engine sends duplicates")
    if len(res2) > 1:
      logger.console("Broker sends duplicates")
    return len(res1) == 1 and len(res2) == 1

##
# @brief Given two files generated by a stream connector, this function checks
# that no events except special ones are sent / replayed twice.
#
# @param str The first file name
# @param str The second file name
#
# @return A boolean True on success
def check_multiplicity_when_engine_restarted(file1: str, file2: str):
    f1 = open(file1)
    content1 = f1.readlines()
    f2 = open(file2)
    content2 = f2.readlines()

    r = re.compile(r".* INFO: ([0-9]+)\s+([0-9a-f]+)\s(.*)$")

    def create_md5_list(content):
        lst = dict()
        for l in content:
            m = r.match(l)
            if m:
                type, md5, js = int(m.group(1)), m.group(2), m.group(3)
                """
                 Are removed:
                   * instance configurations
                   * modules
                   * host checks (they can be done several times
                """
                if type != 65544 and type != 4294901762 and type != 65554 and type != 65561:
                    if md5 in lst:
                        lst[md5] += 1
                    else:
                        lst[md5] = 1
        return lst

    lst1 = create_md5_list(content1)
    lst2 = create_md5_list(content2)

    res1 = set(lst1.values())
    res2 = set(lst2.values())
    return len(res1) == 1 and len(res2) == 1
